{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR 695 Python Seminar\n",
    "> ### Presented by Ramsey Karim\n",
    "\n",
    "Contents:<br>\n",
    "[Section 1: Code Headers](#sec_headers)<br>\n",
    "[Section 2: numpy and scipy](#sec_np)<br>\n",
    "[Section 3: Advanced Plotting](#sec_plotting)<br>\n",
    "[Section 4: astropy](#sec_astropy)<br>\n",
    "[Section 5: Classes and Object-oriented Programming](#sec_classes)<br>\n",
    "[Section 6: Python built-ins](#sec_builtins)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='sec_headers'></a>\n",
    "## 1. Code headers\n",
    "#### Document your code!!!11!\n",
    "\n",
    "I don't usually code in Jupyter Notebooks, so bear with me as I figure out the commands! I usually code in indivudual `.py` files, sometimes strung together in modules. Whether part of a module or a standalone file, I like to start each file with a sort of standardized header including information about what the script is for, when I created it, when I last updated it, and (just in case someone finds it on Github) some contact info.\n",
    "\n",
    "As I'm sure some of you know, you will write excellent, useful code this month, next month, next February. Two or three years later, you will work on a similar problem. You will think to yourself, \"Hey, I have done this before\". You will look for your old code. You will wonder which file that function is in. You will wonder what the function was for, and if/when you modified it.\n",
    "Or, you will return to a project after 6 months and try to quickly pick up where you left off. You will appreciate the date stamps and header text explaining what each file was for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook for the Python seminar, ASTR 695, Fall 2020\n",
    "Created: 2020-09-08\n",
    "Updated: 2020-09-13\n",
    "Presented: 2020-09-14\n",
    "\"\"\"\n",
    "__author__ = \"Ramsey Karim\"\n",
    "__email__ = \"rlkarim@umd.edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will your standard header look like? Check out __[this StackOverflow question](https://stackoverflow.com/questions/1523427/what-is-the-common-header-format-of-python-files)__ for more info and ideas, or search for or invent a header format that works best for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "<a id='sec_np'></a>\n",
    "## 2. `numpy` and `scipy`\n",
    "\n",
    "### 2.1 `numpy`\n",
    "The `numpy` package implements array data types and functions for those array types.\n",
    "\n",
    "Python offers the `list` class as a built-in data type. Python lists are the most \"pythonic\" way to store sequences of objects. The objects do not have to be the same type. You can build  a list of lists to represent a 2D array, and nest for-loops to loop through it. You can change the elements of a list, including adding and removing elements anywhere in the list, without creating a new list.\n",
    "\n",
    "Numpy offers the `numpy.ndarray` class, which creates fixed-size arrays of user-specified dimension, and restricts the array element data type to be the same all throughout the array. You cannot resize the array without making a new one, but you can change the values of array elements.\n",
    "\n",
    "The fixed-size and fixed-type restrictions allow `numpy` functions to work on these arrays _much faster_ than you can process Python `list` items in a for-loop. If you are operating on a set of numbers, I _strongly recommend_ using `numpy` instead of lists.\n",
    "\n",
    "The Python `list` is still very useful! In any case except the above, the `list` may be more efficient and readable. If you need to append/insert/remove elements to/into/from the sequence, lists are great! If your sequence elements are not numbers, but something like strings, user-defined classes, etc, lists are great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2.1.1 When is `numpy` faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the list length (try 100, 10000, 1000000) and rerun the following cells to see how runtime changes.\n",
    "list_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to create an array\n",
    "arr = np.arange(list_length, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "arr += 3\n",
    "arr[arr > 40] *= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similar Python list\n",
    "l = list(float(x) for x in range(list_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, element in enumerate(l):\n",
    "    element += 3\n",
    "    if element > 40:\n",
    "        element *= 5\n",
    "    l[i] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python `list` is faster for small list lengths. However, when you get up to list lengths of $\\sim 10^5$ elements, our simple operation runs around an order of magnitude faster with `numpy.ndarray`.\n",
    "\n",
    "***\n",
    "#### `numpy` functions\n",
    "Numpy has tons of mathematical functions available. If you can use them correctly, they'll be much faster than looping over a Python list. Google around for \"numpy function_I_want\" when you're stuck. If Numpy doesn't have it, Scipy might!\n",
    "\n",
    "When you are using Numpy arrays, use Numpy functions whenever possible! They're fast and they're readable. Don't manually loop over your `numpy.ndarray` if you can avoid it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_as_array = np.array(l)\n",
    "print(f\"Array of shape: {l_as_array.shape}, size: {l_as_array.size}\")\n",
    "\n",
    "print(f\"Mean: {np.mean(l_as_array):.3f}\")\n",
    "print(f\"Median: {np.median(l_as_array):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2.1.2 When should I use a Python `list`?\n",
    "Like I mentioned before, there are times to use a list instead. If your primary operations are appending to a sequence, or removing from a sequence, or something else that won't work well with a pre-sized array, use a `list`. For example, building up a sequence of unknown final length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who knows when our sequence will end!\n",
    "# Change the stop condition and rerun the following cells. Try 1e2 and 1e5\n",
    "unknown_stopping_condition = lambda x: x > 1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Array version\n",
    "i = 0\n",
    "arr = np.array([])\n",
    "while not unknown_stopping_condition(i):\n",
    "    arr = np.append(arr, [i])\n",
    "    i += 1\n",
    "print(f\"Final array size: {arr.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# List version\n",
    "i = 0\n",
    "l = []\n",
    "while not unknown_stopping_condition(i):\n",
    "    l.append(i)\n",
    "    i += 1\n",
    "l_as_array = np.array(l)\n",
    "print(f\"Final array size: {l_as_array.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time we get to $10^5$ elements, the `numpy.ndarray` method takes several seconds, but the list method is still milliseconds. Numpy functions that resize the array often have to build a new array and return that. So instead of reusing the same array in memory most of the time like `list` does, Numpy builds a brand new array every single iteration.\n",
    "\n",
    "#### Into the Weeds:\n",
    "You might have correctly guessed that Numpy arrays are implemented as C arrays under the hood, since they're fixed-size and fixed-type. Python lists are also implemented using C arrays, [but they behave differently](https://stackoverflow.com/questions/3917574/how-is-pythons-list-implemented)! Learn how your data types are implemented in order to use them most efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.2 `scipy`\n",
    "The `scipy`package implements a variety of functions that are useful in scientific applications.\n",
    "\n",
    "I frequently use the `scipy.optimize` library, especially the `curve_fit` and `minimize` functions. I also really like the `scipy.constants` library of fundamental constants (`astropy.constants` offers a similar library. I think you can just pick one to get familiar with).\n",
    "\n",
    "***\n",
    "#### 2.2.1 curve_fit example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Use curve_fit to fit a Gaussian distribution\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Get random number generator from numpy.random\n",
    "# Numpy told me to do this (https://numpy.org/devdocs/reference/random/index.html#random-quick-start)\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Draw a bunch of samples from a Gaussian distribution\n",
    "samples = rng.normal(loc=0., scale=2., size=10000)\n",
    "hist_samples, bin_edges = np.histogram(samples, bins=32)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Make nice, plottable histogram arrays\n",
    "hist_x = np.concatenate(tuple(zip(bin_edges[:-1], bin_edges[1:])))\n",
    "hist_y = np.concatenate(tuple(zip(hist_samples, hist_samples)))\n",
    "plt.plot(hist_x, hist_y, label='Data')\n",
    "\n",
    "# Define your Gaussian function to fit\n",
    "def gaussian(x, mu, sigma, A):\n",
    "    \"\"\"\n",
    "    Nice, simple Gaussian function to give to curve_fit\n",
    "    The first argument must be an array of input values\n",
    "    The rest of the arguments will be fit by curve_fit\n",
    "    :param x: array of input values\n",
    "    :param mu: mean of the distribution\n",
    "    :param sigma: standard deviation of the distribution\n",
    "    :param A: amplitude of the distribution\n",
    "    :returns: array of the same shape as the input array x\n",
    "    \"\"\"\n",
    "    return A * np.exp(-0.5 * (x - mu)**2. / sigma**2.) / (sigma * np.sqrt(2 * np.pi))\n",
    "\n",
    "# Make some initial guesses for the parameters mu, sigma, and A\n",
    "guesses = [1., 3.5, 500]\n",
    "\n",
    "# Send it to curve_fit!\n",
    "popt, pcov = curve_fit(gaussian, bin_centers, hist_samples, p0=guesses)\n",
    "# pcov is the covariance matrix\n",
    "errors = np.sqrt(np.diag(pcov))\n",
    "print(errors)\n",
    "print(f\"True mean = 0, fitted: {popt[0]:.2f} +/- {errors[0]:.3f}\")\n",
    "print(f\"True standard deviation = 2, fitted: {popt[1]:.2f} +/- {errors[1]:.3f}\")\n",
    "print(f\"Fitted amplitude: {popt[2]:.1f} +/- {errors[2]:.1f}\")\n",
    "plt.plot(bin_centers, gaussian(bin_centers, *popt), '--', color='k', label='Fitted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2.2.2 spline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could also try a spline interpolation of that same Gaussian with another scipy function\n",
    "# Splines can be useful for modeling things like bandpass curves, where there's no functional definition\n",
    "# There are 2D spline functions available in scipy as well!\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "spline = UnivariateSpline(bin_centers, hist_samples, s=0)  # Look up this s (smoothing) parameter, it's useful!\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Spline\")\n",
    "plt.plot(hist_x, hist_y, label='Data')\n",
    "plt.plot(bin_centers, spline(bin_centers), '--', color='g', label='Spline')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Spline vs Fit Residuals\")\n",
    "residuals = spline(bin_centers) - gaussian(bin_centers, *popt)\n",
    "plt.plot(bin_centers, residuals, color='r')\n",
    "plt.ylabel(\"Spline $-$ Fit\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of other useful `scipy` functions. `minimize` is an alternative to `curve_fit` that doesn't need x or y array inputs; you give it a function that returns a single number, and then it varies the parameters until it finds the lowest value of that number. It's useful for fitting things that aren't one-dimensional \"x versus y\" problems. There are other interpolation functions in `scipy.interpolate`, which can be helpful while working with images or other data that don't have functional definitions. There are convolution routines in `scipy.signal`, Fourier transform routines in `scipy.fft` ([and](https://stackoverflow.com/questions/6363154/what-is-the-difference-between-numpy-fft-and-scipy-fftpack) `numpy.fft`), integration routines in `scipy.integrate`, linear algebra functions in `scipy.linalg`, stats things in `scipy.stats`. `scipy.spatial` has interesting things like Delaunay and Voronoi triangulation functions, and `scipy.ndimage` has some image processing functions.\n",
    "\n",
    "You can find more `scipy` libraries and their documentation __[here](https://docs.scipy.org/doc/scipy/reference/)__!\n",
    "\n",
    "### Most important takeaway:\n",
    "If you ever find yourself writing up some function that seems pretty fundamental, like some reasonably well-known equation or algorithm, check `numpy`, `scipy`, and `astropy` first. Then Google it, see if it's in another package. Then check other places online, like StackExchange/StackOverflow or Github, to see if you can use/copy code. _Then_ think about writing it yourself.\n",
    "\n",
    "\n",
    "The huge advantage of `numpy`, `scipy`, or `astropy` functions, or functions from other popular libraries, is that they've been tested and are used extensively within the community, so they're pretty trustworthy. They're more readable in your code too, and they're well documented online. Finding it elsewhere online is great for saving time, but remember that it might not have been tested as extensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "<a id='sec_plotting'></a>\n",
    "## 3. Advanced Plotting\n",
    "Everything in this section uses `matplotlib` since that's what I'm most familiar with. I think all this stuff is correct.__*__\n",
    "\n",
    "__*Big huge asterisk__, this is all stuff I learned from experience, so I'm sure if you gave all this notebook to a matplotlib software author, they'd make all kinds of corrections about some stuff I said not being technically correct. But I _can_ guarantee you that this stuff will work. Because I'll prove it. In this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you don't want to run all the previous cells\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.1 `Figure` and `Axes` objects\n",
    "A `Figure` object loosely represents a single plot window, which may itself contain multiple plots, but is a coherent entity that would be saved to one single image file or takes up one single \"window\" in your [window manager](https://en.wikipedia.org/wiki/Window_manager). You can simply create these objects with `fig = plt.figure()`. More info on the `Figure` class [here](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.figure.Figure.html). I don't know what the specific meaning of figures is in jupyter notebooks, and the \"window\" definition seems to be lost in this format.\n",
    "\n",
    "An `Axes` object loosely represents a single plot lying within a `Figure`. A `Figure` may contain more than one `Axes` objects (plots). There is also an `Axis` object in matplotlib, not to be confused with `Axes`, which represents a literal x or y axis, but I won't talk about those. More information on the `Axes` class [here](https://matplotlib.org/3.2.1/api/axes_api.html#the-axes-class).\n",
    "\n",
    "#### Current figure/axes\n",
    "When you have matplotlib.pyplot imported, there is effectively always a current `Figure` and `Axes` object. You can access these through the functions `plt.gcf()` and `plt.gca()` (get current figure/axes). These are what are used whenever you call plot functions directly from `plt` such as `plt.plot(...)`. You can also create your own `Figure` and `Axes` with the functions `plt.figure()` and `plt.subplot()` (these are probably the most commonly used, but there are lots of other ways to make these objects). You can have multiple `Figure` and `Axes` objects created, and edit all of them concurrently, but only one of each will be the \"current\" one reached through `plt.` methods. Lastly, the current `Figure` _must_ contain the current `Axes`, so if you switch axes objects, the current figure may change automatically.\n",
    "\n",
    "You can switch between `Axes` objects using `plt.sca(ax)` (set current axes), where `ax` is the `Axes` object to switch to. If you want to switch back to the last one, you'll need to save it to a variable somewhere!\n",
    "\n",
    "You can switch between `Figure` objects using the `number` attribute. If you have `Figure` object `fig`, you'd call `plt.figure(fig.number)` to switch to `fig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current figures/axes example\n",
    "fig1 = plt.figure()\n",
    "ax1 = plt.subplot()\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = plt.subplot()\n",
    "print(\"We just created fig2.\")\n",
    "print(\"Current figure is fig2?\\n\", plt.gcf() is fig2)\n",
    "print(\"Current axes is ax2?\\n\", plt.gca() is ax2)\n",
    "print()\n",
    "\n",
    "plt.sca(ax1)\n",
    "print(\"We just switched to ax1.\")\n",
    "print(\"Current axes is ax1 now?\\n\", plt.gca() is ax1)\n",
    "print(\"And we automatically switched to fig1?\\n\", plt.gcf() is fig1)\n",
    "\n",
    "plt.figure(fig2.number)\n",
    "print(\"We just switched to fig2.\")\n",
    "print(\"Current figure is fig2?\\n\", plt.gcf() is fig2)\n",
    "print(\"Current axes is ax2\\n\", plt.gca() is ax2)\n",
    "print()\n",
    "\n",
    "try:\n",
    "    print(\"To switch figures, can't we just call plt.scf()?\")\n",
    "    plt.scf(fig1)\n",
    "except Exception as e:\n",
    "    print(\"We could try, but\", end=\" \")\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    print(\"How about just calling plt.figure(fig2)?\")\n",
    "    plt.figure(fig2)\n",
    "except Exception as e:\n",
    "    print(\"Sure, but\", end=\" \")\n",
    "    print(e)\n",
    "\n",
    "fig1.text(0.5, 0.5, \"FIGURE 1\", horizontalalignment='center', fontsize=18) # same as plt.figtext()\n",
    "fig2.text(0.5, 0.5, \"FIGURE 2\", ha='center', fontsize=18); # 0.5, 0.5 is in window coordinates (0 to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the same `plt.` plotting/formatting functions are available as methods of `Axes`, like `plot`, `imshow`, etc. I always just try it first, and if it throws an error, Google it.\n",
    "Some are named differently but behave the same, like `plt.xlabel` versus `ax.set_xlabel`. See the [source code](https://matplotlib.org/3.1.1/_modules/matplotlib/pyplot.html#xlabel) for `plt.xlabel`; it just calls `plt.gca().set_xlabel()`.\n",
    "Some things behave slightly differently, like `plt.xlim` and `ax.set_xlim`/`ax.get_xlim`. See the [source code](https://matplotlib.org/3.1.1/_modules/matplotlib/pyplot.html#xlim) for `plt.xlim`; it checks for arguments and decides which `Axes` method to call.\n",
    "\n",
    "#### Do I have to use `Figure` and `Axes` objects all the time??\n",
    "No, it's not always necessary to use this object-oriented approach to plotting. It can be useful in situations where you're looping over something and want to make several plots each iteration, or when you want to generalize a plotting function to take an `Axes` object as an argument, so that you don't have to copy-paste as much code! My general rule is \"do whatever is fastest and easiest\". Minimize time spent both writing and running code, but also time spent scrolling through your .py file or re-reading 10000 lines of plot copypasta from 2 years ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Into the Weeds\n",
    "This doesn't really help you plot better, so you can skip this, but it's interesting! If you check the type of the result of a `plt.subplot()` call, the returned object isn't `Axes`, it's `AxesSubplot`. I'm not sure of the specifics here, but it seems like matplotlib gives you a subclass of both `Axes` and `SubplotBase`, which has methods for arranging multiple subplots.\n",
    "\n",
    "The SubplotBase [documentation page](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.axes.SubplotBase.html#matplotlib.axes.SubplotBase) explains some of what that class does, and the source code for this function shows how they dynamically generated that `AxesSubplot` class! Learn more about dynamic class creation [here](https://www.python-course.eu/python3_classes_and_type.php) and [here](https://www.geeksforgeeks.org/create-classes-dynamically-in-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.2 plt.subplot2grid\n",
    "You might be familiar with placing multiple subplots in one figure, and the associated [plt.subplot()](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.subplot.html) function for making one subplot at a time. To make multiple at a time (and the figure), you can use [plt.subplots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.subplots.html)&mdash;this one is neat because you can use the `sharex` and `sharey` keywords to tie the axis limits of all the subplots together. But unless you do something really fancy or hacky, these only generate equally-sized subplots on regular grids.\n",
    "\n",
    "[plt.subplot2grid()](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.subplot2grid.html) is a nice way to arrange subplots of varying sizes and dimensions in one figure. Check out the documentation for all the rules. \n",
    "\n",
    "On that documentation page under \"Notes\", it points out that this function is a wrapper function for Gridspec, which I am not personally familiar with. If you get really into making these kinds of plots, you might check out Gridspec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new figure\n",
    "# If we were using a window viewer, this text would be the window title\n",
    "fig1 = plt.figure(\"fresh figure\")\n",
    "\n",
    "# Define the entire grid\n",
    "nrows, ncols = 7, 7\n",
    "# Define the upper left corner of this subplot\n",
    "row, col = 0, 0\n",
    "# Define the right-ward and downward lengths of the subplot\n",
    "rowspan, colspan = 3, 3\n",
    "\n",
    "# Make the first subplot using the above definitions\n",
    "ax1 = plt.subplot2grid((nrows, ncols), (row, col), rowspan, colspan)\n",
    "ax1.fill_between(x=np.arange(10), y1=np.arange(10), y2=np.full(10, 9), color='#008080')\n",
    "\n",
    "# Make another subplot on the same grid, but in a different location and with different dimensions\n",
    "ax2 = plt.subplot2grid((nrows, ncols), (0, 4), 7, 4)\n",
    "ax2.plot(np.sin(np.arange(40)*np.pi/20), np.arange(40)-20)\n",
    "\n",
    "# Make another subplot defined on a different grid\n",
    "ax3 = plt.subplot2grid((8, 8), (4, 0), 4, 4)\n",
    "ax3.fill_between([0, 1, 2, 4, 6, 7, 8], [0, 2, 1.5, 3, 1, 1.5, 0], ec='k', lw=2, alpha=0.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.3 Other useful plotting functions\n",
    "I'll run through some examples of other useful plotting functions\n",
    "#### 3.3.1 `imshow`\n",
    "Show an image, represented by a 2D array, like one pulled from a standard FITS file. You can apply stretches and limits to improve the displayed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a test file from astropy\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "fits_image_filename = get_pkg_data_filename('tutorials/FITS-images/HorseHead.fits')\n",
    "\n",
    "img = fits.getdata(fits_image_filename)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "# Use imshow. Set origin='lower' to make sure image is oriented correctly\n",
    "plt.imshow(img, origin='lower')\n",
    "\n",
    "# We can try to improve the plot by changing the limits and stretch\n",
    "plt.subplot(122)\n",
    "# Use quantile-based approach to vlims. Still usually requires trial and error (for me)\n",
    "img_sorted = np.sort(img.flatten())\n",
    "vmin, vmax = img_sorted[img_sorted.size//100], img_sorted[99*img_sorted.size//100]\n",
    "stretch_fn = lambda x: np.arcsinh(x)\n",
    "plt.imshow(stretch_fn(img), origin='lower', vmin=stretch_fn(vmin), vmax=stretch_fn(vmax))\n",
    "\n",
    "del img # save memory while we're not working here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also show RGB images with imshow. You'll have to stack them so the RGB axis is the last axis, i.e. shape of `[M, N, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for band in ['g', 'i', 'r']:\n",
    "    fits_image_filename = get_pkg_data_filename(f'visualization/reprojected_sdss_{band}.fits.bz2')\n",
    "    imgs.append(fits.getdata(fits_image_filename))\n",
    "\n",
    "# Apply a log stretch\n",
    "# matplotlib.colors offers LogNorm, but it didn't work here for some reason :/\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(111)\n",
    "stretch_fn = np.log\n",
    "for img in imgs:\n",
    "    # Ignore negatives\n",
    "    img_sorted = np.sort(img[img > 0].flatten())\n",
    "    # I usually need to find good vmin/vmax by trial and error...\n",
    "    vmin, vmax = img_sorted[2*img_sorted.size//3], img_sorted[399*img_sorted.size//400]\n",
    "    # Clip the data to the limits and rescale to the (0, 1) interval\n",
    "    img[img < vmin] = vmin\n",
    "    img[img > vmax] = vmax\n",
    "    img[:] = stretch_fn(img)\n",
    "    img -= np.nanmin(img)\n",
    "    img /= np.nanmax(img)\n",
    "# Make (N, M, 3) array for imshow\n",
    "imgs = np.stack(imgs, axis=-1)\n",
    "plt.imshow(imgs, origin='lower')\n",
    "del imgs, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Patches and Colors\n",
    "Matplotlib patches are what the software uses for plotting behind the scenes, but it's sometimes convenient to use them directly. `Patch` is a subclass of `Artist`, [which runs a lot of matplotlib objects behind the scenes](https://matplotlib.org/3.3.1/api/artist_api.html), including that `Axis` object I mentioned earlier. Any kind of artist can be added to an `Axes` instance with the method `ax.add_artist`.\n",
    "\n",
    "There are a [bunch of different kinds](https://matplotlib.org/3.3.1/api/patches_api.html) of Patches. See [the documentation](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.patches.Patch.html) for the `Patch` class for common methods.\n",
    "\n",
    "When you've got a lot of colors on one plot, it's nice to have a little more control over the particular shades, instead of working strictly with red, blue, green, etc. Matplotlib accepts names of extended [web colors](https://en.wikipedia.org/wiki/Web_colors), like `Tomato`, `Thistle`, and `MintCream`. If you want to get creative, you can also specify colors by their RGB hex codes with a leading `#` sign, like `#FF6347` (`Tomato`). The first two characters specify red, the second two green, and the last two blue. They're in hexadecimal, which base-16, so for `10` in base-10, hex uses `A`, up to `F` for base-10 `15`. If you [convert to base-10](https://www.binaryhexconverter.com/hex-to-decimal-converter), `FF 63 47` is `255 99 71`. You can also specify colors to Matplotlib as a tuple of 3 floats in the `[0, 1]` interval, so if you have them as integers from `[0, 255]`, you can just divide by 255. Use a color picker like [this one](https://image-color.com/color-picker.html) to visualize the colors you're specifying and generate the RGB values. The one I linked even suggests other colors for a palette. You can google \"color picker rgb\" or something, there's tons of these.\n",
    "\n",
    "One final thing to consider when choosing colors is how friendly they are to [colorblind](https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/color-blindness/types-color-blindness) readers. When you're making plots for publication or presentation, consider running them through a [colorblindness simulator like this one](https://www.color-blindness.com/coblis-color-blindness-simulator/) and iterating through color schemes until you find a good one. You can also rely on linestyles (for lines) and hatching (for color/2D) to aid in differentiating different lines or regions. I have heard there are also colormaps already designed to be inclusive in this regard. I haven't read up on this extensively, but a quick search turns up [articles like this](https://www.ascb.org/science-news/how-to-make-scientific-figures-accessible-to-readers-with-color-blindness/) which help guide more inclusive figure-making!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot()\n",
    "\n",
    "# Circle, and set a couple appearance keywords\n",
    "circle1 = patches.Circle((0.5, 0.5), 0.23, facecolor='#F4A460', edgecolor='white')\n",
    "circle2 = patches.Circle((0.5, 0.5), 0.2, facecolor='Moccasin', lw=0)\n",
    "ax.add_artist(circle1)\n",
    "ax.add_artist(circle2)\n",
    "# Add more circles in a loop\n",
    "rng = np.random.default_rng()\n",
    "for i in range(15):\n",
    "    dx, dy = 1., 1.\n",
    "    while (dx**2 + dy**2) > 0.18**2:\n",
    "        dx, dy = rng.uniform(low=-0.2, high=0.2, size=2)\n",
    "    circle3 = patches.Circle((0.5+dx, 0.5+dy), 0.02, facecolor='red', lw=0)\n",
    "    ax.add_artist(circle3)\n",
    "\n",
    "# Add a wedge\n",
    "wedge1 = patches.Wedge((0.5, 0.5), 0.23, 5, 35, color='white')\n",
    "ax.add_artist(wedge1)\n",
    "# This wedge was placed afterward the previous patches, so it goes \"on top\" of them\n",
    "# You can manually control where in the \"stack\" of patches this goes using the \"zorder\" keyword\n",
    "# If you need your patch to go on top, use a high value of zorder (like 10000), to place it \"on top\"\n",
    "\n",
    "\n",
    "# Add an arrow to indicate the other patches\n",
    "arrow = patches.Arrow(0.1, 0.9, 0.2, -0.2, width=0.2, color=tuple(x/255. for x in (69, 179, 113)))\n",
    "ax.add_artist(arrow)\n",
    "\n",
    "# Add text\n",
    "ax.text(0.5, 0.8, \"someday we'll have\\npayday pizza again\", ha='center', fontsize=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "<a id='sec_astropy'></a>\n",
    "## 4. `astropy`\n",
    "\n",
    "`astropy` is a core Python package for astronomical computing that implements a variety of useful functions. [You can read more about the project here](https://www.astropy.org/). `astropy` should already be included in your Anaconda distribution of Python, so you shouldn't normally have to worry about downloading or installing it separately.\n",
    "\n",
    "Just like with `numpy` and `scipy`, you can save yourself tons of time and headache by looking for functions in `astropy` before you try to write them yourself. `astropy` has a surprising number of convenient functions and classes ready to go. Stuck on your [unit](https://docs.astropy.org/en/stable/units/) conversions, or found yourself on that [NRAO page](https://science.nrao.edu/facilities/vla/proposing/TBconv) about converting flux to [brightness temperature](https://docs.astropy.org/en/stable/api/astropy.units.brightness_temperature.html#astropy.units.brightness_temperature)?? `astropy` has what you need.\n",
    "\n",
    "***\n",
    "### 4.1 FITS I/O\n",
    "I don't know about theorists, but most observers will deal in FITS files pretty frequently. To be honest, I don't know how to access their data in Python _without_ `astropy`.\n",
    "\n",
    "FITS files contain informative headers, which have their own [standard, archaic format](https://fits.gsfc.nasa.gov/fits_dictionary.html), and data, which is either a table or _n_-D array. I'm not as familiar with the table version, but `astropy.io.fits` can handle that just fine too.\n",
    "\n",
    "`astropy.io.fits` implements several Python classes that represent various parts of these files. The headers are represented by the `Header` class, which behaves like (but is not subclassed from) a Python `dict`. The image data arrays are represented by `ImageHDU` objects ([read more here](https://docs.astropy.org/en/stable/io/fits/api/images.html#imagehdu)). According to [the main astropy FITS page](https://docs.astropy.org/en/stable/io/fits/), \"an HDU (Header Data Unit) is the highest level component of the FITS file structure, consisting of a header and (typically) a data array or table\". Objects representing HDUs (usually `ImageHDU`) are wrapped in `list`-like `HDUList` objects when loaded from or saved to files.\n",
    "\n",
    "FITS files sometimes contain several extensions, which are similarly-shaped data arrays with their own headers all wrapped up in one file. For example, the first extension might be the data, the second might be uncertainty, the third might be coverage, etc.\n",
    "A multi-extension FITS file will sometimes have a global header, one header without any data.\n",
    "For these, the global header is contained in the `PrimaryHDU` object, and the image extensions are contained in `ImageHDU` objects. All of these are collected in an `HDUList`, with the `PrimaryHDU` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# This is just for demo purposes, astropy has some nice test images\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "fits_image_filename = get_pkg_data_filename('tutorials/FITS-images/HorseHead.fits')\n",
    "# Ordinarily you'd have your own FITS file, since you wouldn't just be doing this for fun\n",
    "\n",
    "# Get the data from a single-extension file using the getdata convenience function\n",
    "# If the file is multi-extension, gets the first HDU with data\n",
    "img, hdr = fits.getdata(fits_image_filename, header=True)\n",
    "print(f\"Loaded an image with dimensions {img.shape}\")\n",
    "print(f\"The image was observed at {hdr['TELESCOP']} using {hdr['INSTRUME']}\")\n",
    "# You could print the whole header, too\n",
    "print_long_thing = False\n",
    "if print_long_thing:\n",
    "    print(hdr.tostring(sep='\\n'))\n",
    "    \n",
    "del img, hdr\n",
    "# Open the HDUL manually (useful for multi-extension cubes, or when you don't know if it's single or multi)\n",
    "# The \"with\" statement helps you open and close files/streams cleanly!\n",
    "with fits.open(fits_image_filename) as hdul:\n",
    "    print(f\"This file has {len(hdul)} extensions\")\n",
    "    print()\n",
    "    if len(hdul) > 1:\n",
    "        for i in range(len(hdul)):\n",
    "            print(f\"The {i}th extension is a {type(hdul[0]).__name__}\")\n",
    "            if 'EXTNAME' in hdul[i].header:\n",
    "                print(f\"The extension is named \\\"{hdul[i].header['EXTNAME']}\\\"\")\n",
    "            else:\n",
    "                print(\"The extension doesn't have a name\")\n",
    "            if hasattr(hdul[i].data, 'shape'):\n",
    "                print(f\"It contains an array of shape {hdul[i].data.shape}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [intro page](https://docs.astropy.org/en/stable/io/fits/) for this package has thorough instructions on how to open and save FITS files, so I won't spend too much time on this. One thing I have found useful in the past that I'll share is some boilerplate for writing your own FITS header.\n",
    "\n",
    "Usually when saving FITS files, I just copy a header from one that I opened, but sometimes that doesn't make sense, or I feel like the info in the header would be misleading. In those cases, I'll make a bare-bones header with some useful keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "# Quick example of the header keywords I might throw in (taken from my code)\n",
    "\n",
    "hdu = fits.PrimaryHDU()\n",
    "hdu.header['EXTNAME'] = 'T' # this was a temperature\n",
    "hdu.header['BUNIT'] = 'K'\n",
    "hdu.header['OBJECT'] = 'perseus'\n",
    "hdu.header['DATE'] = (datetime.datetime.now(datetime.timezone.utc).astimezone().isoformat(), \"File creation date\")\n",
    "\n",
    "try:\n",
    "    # when your script is in a regular .py file, __file__ will give the filename\n",
    "    hdu.header['CREATOR'] = (f\"Ramsey: {__file__}\", \"FITS file creator\")\n",
    "except NameError as e:\n",
    "    print(f\"This is a jupyter notebook, so {e}\")\n",
    "    # jupyter notebook doesn't define __file__ :/\n",
    "    hdu.header['CREATOR'] = (\"Ramsey: jupyter notebook\", \"FITS file creator\")\n",
    "hdu.header['HISTORY'] = \"Ramsey wrote this inpainting code on on Jan 13 2020.\"\n",
    "hdu.header['HISTORY'] = f\"Cutoff: N={1e21:4.0E}. Value from talks with LGM.\"\n",
    "hdu.data = np.zeros((20, 20)) # or some more important data\n",
    "hdu.header['COMMENT'] = \"Other important notes you want to put in\"\n",
    "hdulnew = fits.HDUList([hdu]);\n",
    "\n",
    "# hdulnew.writeto(\"some_filename.fits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WCS\n",
    "I am absolutely _not_ going very deep into WCS (world coordinate system), because I jump down that rabbit hole every 2 months or so, and I've never seen the end. I don't know how old that system is. Too old. Too archaic.\n",
    "The `astropy.wcs` library makes it pretty easy to work with this stuff without having to know whatever horrors lie underneath. It's all fun and games until your FITS header has some tiny little problem.\n",
    "\n",
    "One big warning about the (current) `astropy` WCS package: it's heavily based on (or a wrapper for) some other older code, `wcslib`. I don't know how deep this thing goes.\n",
    "\n",
    "[WCS](https://fits.gsfc.nasa.gov/fits_wcs.html) is how FITS files representing astronomical images or data define the spatial coverage of their data. Specifically, it's a set of FITS header keywords that define a sky coordinate for each pixel in the image. Those keywords generally define a reference pixel somewhere in the image and a reference coordinate (like RA, DEC) to tie to that pixel, and then they define a matrix that transforms pixel distances to sky coordinate distances. If anyone wants to talk more about this, I would love to learn from you about this or share what I've learned.\n",
    "\n",
    "To get WCS information from a FITS file, you just call the `WCS` object constructor on the FITS `Header`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs import WCS\n",
    "\n",
    "fits_image_filename = get_pkg_data_filename('tutorials/FITS-images/HorseHead.fits')\n",
    "img, hdr = fits.getdata(fits_image_filename, header=True)\n",
    "\n",
    "wcs_object = WCS(hdr)\n",
    "\n",
    "print(wcs_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this WCS object to find the sky coordinates of given pixels (`wcs_object.pixel_to_world`) (although watch out, pixels are `xy`-indexed, which is the opposite of `numpy` array indexing), or the pixel coordinates of a sky coordinate (`wcs_object.world_to_pixel`). Or if the flipped pixel index bothers you, you can use the `array_index_to_world` (and vice versa) versions of those functions&mdash;but watch out, array indices need to be integers!! LOL!!\n",
    "\n",
    "Another useful function `astropy.wcs` offers is `wcs_obj.footprint_contains`, which will tell you if a given coordinate is contained in this image.\n",
    "\n",
    "Check out the [list of WCS class attributes and methods](https://docs.astropy.org/en/stable/api/astropy.wcs.WCS.html#astropy.wcs.WCS) to see what functions you might use.\n",
    "\n",
    "***\n",
    "\n",
    "### 4.3 SkyCoord\n",
    "SkyCoord has significantly improved my life. From the `astropy` [coordinates](https://docs.astropy.org/en/stable/coordinates/index.html) library, this class representes astronomical sky coordinates _and does all the transformations between different coordinate systems_. You can read in sky coordinates in a variety of formats and print them out different ways too. You can calculate the angular separation or position angle between coordinates, or find a coordinate given an angular separation and position angle from another. It's great, I love it.\n",
    "\n",
    "Certain `WCS` functions naturally return `SkyCoord` objects. I sometimes use the following trick to find the pixel scale of an image directly. If you have better suggestions of how to do this, I'd love to learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Grab the coordinates of two adjacent pixels\n",
    "c1, c2 = wcs_object.pixel_to_world(0, 0), wcs_object.pixel_to_world(0, 1)\n",
    "pixel_scale = c1.separation(c2)\n",
    "print(f\"The pixel scale of the image is {pixel_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, right? That pixel scale even has units! Would be nice to convert those degrees into something more reasonable...\n",
    "\n",
    "***\n",
    "\n",
    "### 4.4 Units\n",
    "I only discovered the power of `astropy.units` somewhat recently. [This library](https://docs.astropy.org/en/stable/units/) has `Unit` and `Quantity` classes that represent base units and values with associated units, respectively. You would mostly work with `Quantity` objects, which is what happens when you multiply a number or array by a `Unit` or another `Quantity`. When you add or multiply `Quantity` objects with different units, it will figure out the conversions to make, or make new units, or yell at you (when appropriate).\n",
    "\n",
    "Check out the introduction page (linked above), where they give a bunch of neat examples of what you can do with this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "# Easy conversions, just use Unit objects like u.arcsec (see the documentation for a full list)\n",
    "print(f\"The pixel scale of the image is {pixel_scale.to(u.arcsec):.2f}\")\n",
    "print(f\"1000 pixels would be {(1000*pixel_scale).to(u.arcmin):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "<a id='sec_classes'></a>\n",
    "## 5. Classes and Object-oriented Programming\n",
    "\n",
    "When you either code directly in your interpreter or write a column of mostly left-aligned code, working line by line in the main file, that's generally called [scripting](https://en.wikipedia.org/wiki/Scripting_language). When you group your code into functions and use those as the main components of your code, that's generally called something like [procedural](https://en.wikipedia.org/wiki/Subroutine) or [functional programming](https://en.wikipedia.org/wiki/Functional_programming). When you organize concepts in your code into data structures that have their own attributes (like data, information) and methods (functions), that's called [object-oriented programming](https://en.wikipedia.org/wiki/Object-oriented_programming) (OOP).\n",
    "\n",
    "Apologies if I misused any of these terms; I think this is mostly accurate, at least in my experience. Most importantly, there's no hierarchy to these programming styles. Different languages use different paradigms, and Python happens to support all of the styles I mentioned above. All of them have advantages and trade-offs. Use whatever style or combination works best for you for a particular task.\n",
    "\n",
    "Object-oriented is pretty popular in software, and is the fundamental style of languages like Java and C++. There are lots of resources online on how to write classes in Python, like [this one](https://www.geeksforgeeks.org/python-classes-and-objects/). I'll try to stick to short examples and point out where to look for more information.\n",
    "\n",
    "***\n",
    "### 5.1 Classes\n",
    "When you work with classes, you have the _class,_ which is a sort of abstract concept of the class, like the idea of a tree, and then you have an _instance_ of that class, which is a real version of that class, like the tree you have in your backyard. The idea of a \"tree\" and the physical tree in your backyard are different. Your tree is a tree, but \"a tree\" is not _your_ tree. There can be lots of other trees, and they have just as much claim to the idea of trees as yours does. In practice, what this means is there can be class attributes and instance attributes. Instance attributes, what you'll work with primarily, are variables attached to the instance. Instances generally have the same attributes, but the values of those attributes may differ. Like, all trees have leaves and branches, but the specific number of branches or leaves differs.\n",
    "\n",
    "Classes can also inherit from other classes. You can basically \"copy\" everything from an existing class, and then modify or add to it. The idea of a tree inherits from the idea of a plant; all trees are plants, not all plants are trees. In OOP, this is called subclassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models\n",
    "\n",
    "# Define a class, use whatever name is most descriptive\n",
    "class DustModel:\n",
    "    \"\"\"\n",
    "    DustModel class\n",
    "    Author: Ramsey Karim\n",
    "    Created: September 13, 2020\n",
    "\n",
    "    I don't know the style guidelines for class documentation, but couldn't hurt to have some\n",
    "    general information here, right?\n",
    "    \"\"\"\n",
    "    \n",
    "    # the __init__ function initializes the instance of the class\n",
    "    def __init__(self, T, N, beta=2.0):\n",
    "        \"\"\"\n",
    "        DustModel representing an isothermal column of interstellar dust.\n",
    "        Model only valid in the far-infrared.\n",
    "        :param T: Quantity, temperature of the dust\n",
    "        :param N: Quantity, column density of the dust\n",
    "        :param beta: (optional) float, far-infrared spectral index\n",
    "        \"\"\"\n",
    "        # initialize the instance attributes\n",
    "        self.T = T\n",
    "        self.bb = models.BlackBody(temperature=T)\n",
    "        self.N = N\n",
    "        self.beta = beta\n",
    "\n",
    "    # regular class methods always need \"self\" as the first argument\n",
    "    # \"self\" is the instance!\n",
    "    def radiate(self, nu):\n",
    "        \"\"\"\n",
    "        Model the flux emitted from the dust at the given frequencies or wavelengths\n",
    "        :param nu: Quantity, frequency equivalent\n",
    "        \"\"\"\n",
    "        nu = nu.to(u.Hz, equivalencies=u.spectral())\n",
    "        source_flux = self.bb(nu)\n",
    "        # optical depth (I think)\n",
    "        tau = (u.M_p * self.N * (0.1 * (nu/(1000*u.GHz))**self.beta * u.cm**2 / u.g)).decompose()\n",
    "        return source_flux * (1 - np.exp(-tau))\n",
    "\n",
    "    # Methods surrounded by underscores are usually special Python things\n",
    "    # They can help your object interact in more \"pythonic\" ways\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Some short string to describe the object roughly\n",
    "        \"\"\"\n",
    "        return f\"DustModel(T={self.T:.1f})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        A little more descriptive (at least, that's how I usually use __repr__)\n",
    "        \"\"\"\n",
    "        return f\"<DustModel ({self.T:.1f}), ({self.N:.1E}), (beta={self.beta})>\"\n",
    "\n",
    "    # Can define what happens \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Call the DustModel.radiate function\n",
    "        \"\"\"\n",
    "        return self.radiate(*args, **kwargs)\n",
    "\n",
    "    \n",
    "d = DustModel(25*u.K, 1e21/u.cm**2)\n",
    "print(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = (10**np.arange(1, 3, 0.05)) * u.micron\n",
    "flux = d(wavelength)\n",
    "print(f\"Flux originally in units of {flux.unit}\")\n",
    "plt.plot(wavelength.to(u.GHz, equivalencies=u.spectral()), flux.to(u.MJy/u.sr), color='k')\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(f\"Flux (MJy/sr)\")\n",
    "plt.xscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.2 Modular programming\n",
    "_Quick note about this notebook:_ Modular programming isn't well aligned with how Jupyter notebooks operate, so I won't show any examples in this notebook. You can probably try to use some concepts of modular programming with notebooks (maybe, I've never tried), but it's vastly more common for modular programming to be used with plain `.py` files organized into folders.\n",
    "***\n",
    "\n",
    "Another useful programming concept is the idea of [modular programming](https://en.wikipedia.org/wiki/Modular_programming). Modular programming is a way to [organize code](https://www.geeksforgeeks.org/modular-approach-in-programming/) into different files, called \"modules\". If you're familiar with this style, you may have noticed that it seems similar to object-oriented programming! You define classes which represent some kind of object (like a tree) that has attributes (like number of leaves, root pattern) and methods (\"grow taller\", \"drop branch on car\"), and can be instanced (the tree in your back yard or outside your office). When you organize your code into modules, you're organizing a bunch of functions and classes that operate on related data or achieve a general goal. It's a library of functions! They can be used for different things, but they're all related.\n",
    "\n",
    "Modules behave a little like classes in Python in that you can call functions from them similarly to class methods. However, modules aren't instanced. It wouldn't make sense. In our tree example, a related module might be Gardening, which has functions to prune and water trees, maybe implements a Bee class to help pollinate. All of these fall under the umbrella of gardening, but you don't expect to instance Gardening and hold something in your hand and say \"This item is a Gardening\".\n",
    "\n",
    "If you've taken a look at the source code for Python packages, you can see modular programming all over the place.\n",
    "Check out the [Astropy Github](https://github.com/astropy/astropy/tree/master/astropy) to see the way Astropy organizes their code. If you click the `wcs` library (which is just a folder under `astropy/`), you'll find an `__init__.py` file, some `.py` files, and a couple directories with code in them as well. Those directories also have `.py` files and an `__init__.py` file.\n",
    "\n",
    "Click on the `__init__.py` file under `astropy/wcs`. It's a short file, mostly importing everything from the `wcs.py` file in that same directory, and then importing the `utils.py` module by name.\n",
    "`utils.py` is a file being treated as a module of its own. You can look at that file and find a bunch of functions, all related by their general goals of supporting the WCS package, and you can import all of them under the name `utils`, and you can access them by dot-notation, like `utils.add_stokes_axis_to_wcs`.\n",
    "\n",
    "One quick thing about importing: whenever you import a module, what happens (at least what I believe generally happens) is all the code in that file is \"run\", so that you have those variable, function, and class definitions ready to go in your current file. If you have left-aligned code, that will run too. When you decide to reuse functions from old code, make sure you don't have unecessarily expensive left-aligned code in that old file. Every time you import stuff from that file, you'll run that code. A way around this is the `if __name__ == \"__main__\":` statement. If you put all your \"left-aligned\" code under one of these, it will _ony_ run if you specifically ran this file in terminal; it will not run when this file is imported into another.\n",
    "\n",
    "Back to Astropy. The `wcs.py` is not so much being treated as a module here. You can import all the functions from it directly, with the `*` notation you see in the `__init__.py` file. This means you will no longer be able to tell the difference between functions you wrote in the current file and functions you imported. You can access the functions just fine, same as with `utils`, but you don't need to use `wcs.<function_name>` dot-notation, you just call `<function_name>`. When you read about this style of importing, you're usually warned against using this too much, since it can cause confusion (especially in larger files) as to whether some function was defined here by you, or was imported from somewhere else.\n",
    "\n",
    "However, you can also use `from <module> import *` to _hide_ where that stuff came from. That's sort of what they're doing here. First, we need to talk about what that `__init__.py` file is doing. It turns out that, if you were to back up into the `astropy/` directory, you can import the _folder_ `wcs` like a module. The entire _directory_ becomes a module! But it needs that `__init__.py` file to _know_ that it's a module, otherwise you'll just get an error. If you just want to be able to chain through the directory to import specific files underneath, you can leave the `__init__.py` file empty! The issue is that, in that case, you have to know what's under that directory. Let's import the `WCS` object from the `wcs.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs.wcs import WCS\n",
    "\n",
    "WCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It worked. But it typing `.wcs.` just to jump through that directory felt redundant. What if the directory just knew what we'd want from it?\n",
    "\n",
    "The `__init__.py` file can do that too! Like I said earlier, when you import a file, all the code in that file is run. When you import a directory, only what is in the `__init__.py` file is run. If you import something to that `__init__.py` file, then the directory knows about it, and you can just get it from the directory next time!\n",
    "\n",
    "Since the `wcs/` directory imported `*` from `wcs.py`, it knows about the `WCS` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs import WCS\n",
    "\n",
    "WCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same object! We can make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs.wcs import WCS as WCS_fromfile\n",
    "from astropy.wcs import WCS as WCS_fromdir\n",
    "\n",
    "print(WCS_fromfile is WCS_fromdir) # They're the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have access to that `utils` file in the WCS directory. I don't know what the difference between importing that into `__init__.py` or just letting people import that file through the directory is. Maybe it's more clear that this is part of the API? Either way, it's the exact same import statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs import utils\n",
    "# or something like this, since \"utils\" is pretty nonspecific\n",
    "from astropy import wcs\n",
    "# It's the same library at the end of the day\n",
    "print(wcs.utils is utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This style of programming works great with the concept of [abstraction barriers](https://en.wikibooks.org/wiki/Object_Oriented_Programming/Abstraction_Barrier), which I will not go into here, but which I recommend reading about if you're interested in designing software!\n",
    "\n",
    "Modular programming is something I am actively trying to learn more about! I think it's a really neat way to organize code, especially if I plan to put stuff on Github for others to see/use. If anyone has experience with this, I'd love to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='sec_builtins'></a>\n",
    "## 6. Python built-ins\n",
    "The Python language has a [small number of built-in functions/classes](https://docs.python.org/3/library/functions.html). These are the core of the language, and even though we rely heavily on `numpy`, `scipy`, `astropy`, and other external libraries, these built-ins are still powerful and can be used effectively!\n",
    "\n",
    "A few of these are not functions, but objects, and you're probably very familiar with some of them. There's primarily the `list`, the dictionariy `dict`, the `tuple`, and the `set` and `frozenset`.\n",
    "\n",
    "***\n",
    "### 6.1 Mutable vs immutable types\n",
    "Objects in Python can either be mutable or immutable. [This article](https://medium.com/@meghamohan/mutable-and-immutable-side-of-python-c2145cf72747) gives a thorough explanation of these concepts (with a cool figure at the beginning!), but in brief, mutable objects can have their contents changed, and immutable objects cannot.\n",
    "A `list` is mutable, but a `tuple` is not. Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"list:\")\n",
    "a = [10, 20]\n",
    "print(f\"a[0] = {a[0]}\")\n",
    "a[0] = 30\n",
    "print(\"a:\", a)\n",
    "print()\n",
    "\n",
    "print(\"tuple\")\n",
    "b = (10, 20)\n",
    "print(f\"b[0] = {b[0]}\")\n",
    "try:\n",
    "    b[0] = 30\n",
    "except Exception as e:\n",
    "    print(f\"There was a problem: {e}\")\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are unable to modify the tuple, since it is immutable. This isn't necessarily a bad thing; it can be useful to know that certain values cannot be changed!\n",
    "\n",
    "***\n",
    "### 6.2 Hashing\n",
    "Another concept worth mentioning here is [hashing](https://en.wikipedia.org/wiki/Hash_function), which the generalized act of converting an arbitrary chunk of data (like any object in Python) into a fixed-length value (like an integer). The name pretty much means \"to chop up\" or \"make a mess of\", like a breakfast hash! One of the key qualities of a hash function is that it should map a unique object to a unique number, as best as possible. If two instances of objects can be considered \"equal\", then they should has to the same number, and if they can be considered \"unequal\", they should hash to different numbers. These are used for a variety of computer science data structures and algorithms, including cryptography, but more relevant to us, the concept of [hash tables](https://en.wikipedia.org/wiki/Hash_table).\n",
    "\n",
    "#### 6.2.1 Motivation for hash tables\n",
    "You can definitely read the Wikipedia articles and search for other resources on this if you're interested, but I'll give a brief motivation for why this stuff is useful to us.\n",
    "\n",
    "When you make a list with a number of elements, and you want to retrieve and element, you can do so either by the index or by the item itself. Since a Python `list` is implemented with a C-array, accessing by index is really fast! Your computer knows exactly where to find that element, since you effectively gave it the memory address.\n",
    "But what if you want to find a particular element, and don't know where in the list it might be? In that case, since the C-array and Python `list` don't \"know\" anything about what they contain, you'd have to search through the entire list until you found what you're looking for.\n",
    "\n",
    "That means that the longer your list is, the more time this takes. What if you could sort of tell your list what was in it? Picture this: you quickly turn your object into an integer (somehow, doesn't matter how), and you use part of that integer as an index to place your item somewhere in the list. If you want to look for that item in your list, you hash it again and check that area in your list. The tradeoff is that you don't know how your list is actually organized (since the hashing should be done behind the scenes), so you can't place any meaning in the order of the list.\n",
    "\n",
    "This kind of hash table is implemented in Python as the `set`. You can add items to the `set`, but items in the set need to be unique, and you can't access them by index. It's a nice way of collecting unique items and quickly checking if you already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()\n",
    "a.add(10)\n",
    "a.add(30)\n",
    "a.add((1, 20))\n",
    "print(10 in a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets have restrictions on what can be put in them. Because hashing should be unique to the object's \"value\", it must depend on the attributes of that instance (and not the memory location or something like that). Because you need to use the hash function to retrieve the object, that hash function can't change over time. Thus, you can only include in a `set` objects whose values cannot be changed: immutable objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()\n",
    "l = [10]\n",
    "t = (10,)\n",
    "print(f\"I have a {type(l).__name__} = {l} and a {type(t).__name__} = {t}\")\n",
    "\n",
    "try:\n",
    "    a.add(t)\n",
    "    print(\"I added the tuple to the set\")\n",
    "except Exception as e:\n",
    "    print(\"There was a problem adding the tuple to the set:\", e)\n",
    "\n",
    "try:\n",
    "    a.add(l)\n",
    "    print(\"I added the list to the set\")\n",
    "except Exception as e:\n",
    "    print(\"There was a problem adding the list to the set:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples are useful because they can be added to sets! You might store a coordinate pair, something where order matters and the values shouldn't change, to a set to keep track of unique coordinates.\n",
    "\n",
    "Sets themselves are mutable (you can `.add` to them), so they cannot be added to other sets. The `frozenset` is an immutable hash table, so it can be added to a `set`! You can call the `frozenset` constructor on a sequence (including an existing `set`) to create a new `frozenset` instance. You can use all the same lookup functions, but you cannot add or remove items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()\n",
    "a.add(40)\n",
    "a.add(50)\n",
    "b = set()\n",
    "b.add((1, 20))\n",
    "print(f\"set b = {b}\")\n",
    "\n",
    "# Try to add a to set b\n",
    "try:\n",
    "    b.add(a)\n",
    "except Exception as e:\n",
    "    print(\"There was a problem adding set a to set b:\", e)\n",
    "\n",
    "frozen_a = frozenset(a)\n",
    "try:\n",
    "    b.add(frozen_a)\n",
    "    print(f\"Added frozenset(a): set b = {b}\")\n",
    "except Exception as e:\n",
    "    print(\"There was a problem (but there shouldn't be!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Frozenset example\n",
    "\n",
    "The `frozenset` class can be useful for representing sequences of objects whose order shouldn't be considered, like the vertices of a triangle. To represent a triangle as a properly hashable construct, you could represent your coordinates as tuples (order matters, hashable), and then store 3 tuples in a `frozenset`, where the order doesn't matter, so any combination of those three coordinates will return an \"identical\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triangle:\n",
    "    \"\"\"\n",
    "    Triangle class\n",
    "    Author: Ramsey Karim\n",
    "    Created: September 13, 2020\n",
    "    \"\"\"\n",
    "    def __init__(self, *coords):\n",
    "        \"\"\"\n",
    "        Triangle represents a 3-pointed triangle in n-D\n",
    "        :param coords: sequence arguments representing the vertices. All sequences must be the same length.\n",
    "            Exactly 3 sequences must be given as arguments.\n",
    "        \"\"\"\n",
    "\n",
    "        # Make sure you gave 3 arguments\n",
    "        try:\n",
    "            assert len(coords) == 3\n",
    "        except AssertionError:\n",
    "            raise RuntimeError(f\"You cannot make a triangle out of {len(coords)} vertices\")\n",
    "        \n",
    "        # Make sure your arguments are sequences\n",
    "        try:\n",
    "            assert (hasattr(c, '__iter__') for c in coords)\n",
    "        except AssertionError:\n",
    "            raise RuntimeError(\"Your coordinates must be sequences\")\n",
    "        \n",
    "        # Convert coordinates to tuples (just in case)\n",
    "        coords_as_tuples = [tuple(c) for c in coords]\n",
    "        # Make sure all tuples are the same length\n",
    "        self.n_dim = len(coords_as_tuples[0])\n",
    "        try:\n",
    "            assert all(len(c) == self.n_dim for c in coords_as_tuples)\n",
    "        except:\n",
    "            raise RuntimeError(\"Your coordinates must be of the same dimension\")\n",
    "        \n",
    "        self.vertices = frozenset(coords_as_tuples)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Triangle{str(self.vertices).replace('frozenset', '')}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Hash on the internal frozenset(tuple) structure\n",
    "        \"\"\"\n",
    "        return hash(self.vertices)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Rely on the frozenset(tuple) for equality\n",
    "        :param other: the object being compared to (should be a Triangle)\n",
    "        \"\"\"\n",
    "        return self.vertices == other.vertices\n",
    "\n",
    "\n",
    "# Now let's test this structure!\n",
    "first_coords = [(0, 0), (0, 2), (1, 1)]\n",
    "second_coords = [(0, 0), (0, 1), (1, 0)]\n",
    "same_coords_as_first_coords = [(0, 2), (1, 1), (0, 0)]\n",
    "\n",
    "first_tri = Triangle(*first_coords)\n",
    "same_as_first_tri = Triangle(*first_coords) # same coordinate tuple objects\n",
    "second_tri = Triangle(*second_coords)\n",
    "same_coords_as_first_tri = Triangle(*same_coords_as_first_coords) # same numbers but different tuple objects\n",
    "\n",
    "print(first_tri)\n",
    "print(f\"Same as itself? {first_tri == first_tri}\")\n",
    "print(f\"Same as a Triangle with same coordinate tuple objects? {first_tri == same_as_first_tri}\")\n",
    "print(f\"Same as a Triangle with same coords, different tuple objects? {first_tri == same_coords_as_first_tri}\")\n",
    "print(f\"Same as a DIFFERENT triangle? {first_tri == second_tri}\")\n",
    "print()\n",
    "\n",
    "a = set()\n",
    "a.add(first_tri)\n",
    "a.add(second_tri)\n",
    "print(f\"Set a = {a}\")\n",
    "\n",
    "print(f\"Can we find identical Triangles (but different Triangle objects) in the set?\")\n",
    "print(same_as_first_tri in a)\n",
    "print(same_coords_as_first_tri in a)\n",
    "print()\n",
    "\n",
    "print(f\"Are they the same objects?\")\n",
    "print(same_as_first_tri is a)\n",
    "print(same_coords_as_first_tri is a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the `dict` object. You might be familiar with these as ways to match keys with values, which can be really helpful! It turns out that Python dictionaries are just souped up sets; they're hash maps. They keys are hashed, and the values are looked up with those keys.\n",
    "\n",
    "Use lists and tuples when order matters, or when you're focusing on the index. Use sets, frozensets, and dictionaries when you're focusing on unique membership, and order doesn't matter. And remember that, for small lists (10s of elements), the performance really doesn't matter.\n",
    "\n",
    "***\n",
    "### 6.3 Generators and other iterables\n",
    "All the types we just went through represent some sort of sequence of objects. The dictionaries are a little special, since they have both the keys and the values, but you could consider a sequence of key-value pairs (in concept). All these \"sequence\" types are __iterable__, which conceptually means they represent some sequence of objects, and more specifically means (in Python) that they have the `__iter__` method.\n",
    "\n",
    "When the `__iter__` attribute is called, an object called an `iterator` is returned. An `iterator` is a single-use object that has a `__next__` method. Each time you call `__next__`, the `iterator` returns an object from the sequence. When it runs out of objects to return, it throws an error to say that it's empty. At that point, you just throw it out, you don't reuse it.\n",
    "\n",
    "For-loops in Python call the `__iter__` method of an iterable object and then loop over the returned `iterator` object. You can call this yourself with the built-in `iter` function, and you can call the `__next__` method with the built-in `next` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "print(f\"List a is iterable? {hasattr(a, '__iter__')}\")\n",
    "\n",
    "iter_a = iter(a)\n",
    "print(f\"Iter(a) = {iter_a}\")\n",
    "\n",
    "print(f\"next(a) = {next(iter_a)}\")\n",
    "print(f\"next(a) = {next(iter_a)}\")\n",
    "print(f\"next(a) = {next(iter_a)}\")\n",
    "print(f\"next(a) = {next(iter_a)}\")\n",
    "try:\n",
    "    print(f\"next(a) = {next(iter_a)}\")\n",
    "except Exception as e:\n",
    "    print(\"Done! \", type(e).__name__)\n",
    "\n",
    "print()\n",
    "print(f\"List a = {a} is unchanged!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can implement the `__iter__` method of your own class if you want to be able to naturally loop over it; you'd probably just want to return the `iterator` from some iterable attribute. If you decide to try this, look into it further! I have only tried this once and did not do extensive testing, so I am definitely no expert. I just think it's super cool :-)\n",
    "\n",
    "You could also build your own iterable from scratch, in a way, using a `generator`. That's another Python type, but you can define them a little differently than most of these types. Check this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function. This function, when called, returns a generator object, which works like an iterator\n",
    "def fibonacci():\n",
    "    n_minus_1 = 0\n",
    "    n = 1\n",
    "    while True:\n",
    "        yield n + n_minus_1\n",
    "        n_plus_1 = n + n_minus_1\n",
    "        n_minus_1 = n\n",
    "        n = n_plus_1\n",
    "\n",
    "print(\"The first two fibonacci numbers are 0 and 1\")\n",
    "fib_iter = fibonacci()\n",
    "for i, f in enumerate(fib_iter):\n",
    "    if i > 15:\n",
    "        break\n",
    "    print(f\"The {i+3:2d}th fibonacci number is {f:5d}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Start over with new iterator\n",
    "fib_iter = fibonacci()\n",
    "i, f = 0, 0\n",
    "print(\"The first two fibonacci numbers are 0 and 1\")\n",
    "while i < 16:\n",
    "    i += 1\n",
    "    f = next(fib_iter)\n",
    "    print(f\"The {i+3:2d}th fibonacci number is {f:5d}\")\n",
    "\n",
    "print()\n",
    "print(type(fibonacci))\n",
    "print(type(fib_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty cool, because I'm able to loop over the Fibonacci sequence like it's all in some single list. I don't even know it's not, right? But it can't possibly be in a single list, because it's infinite. One of the powers of generators is [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation), which means that the items in this kind of sequence aren't created until they're needed. This can allow you to iterate over infinite sequences (and make your own stop conditions in other parts of the code), or to iterate over a sequence of very memory-intensive objects without putting them all in a list at once.\n",
    "\n",
    "Finally, there is a really nice shorthand for creating all these sequence types: [comprehensions](https://www.geeksforgeeks.org/comprehensions-in-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension\n",
    "x2 = [x**2 for x in range(10)]\n",
    "\n",
    "# Can also filter\n",
    "x_even = [x for x in range(20) if x%2 == 0]\n",
    "\n",
    "# Tuple comprehension\n",
    "t = tuple(x**3 for x in x2)\n",
    "\n",
    "# Set comprehension\n",
    "s = {x + 3 for x in t}\n",
    "\n",
    "# Dict comprehension\n",
    "d = {x: y for x, y in zip(x2, x_even)}\n",
    "\n",
    "# Generator comprehension\n",
    "g = (np.full((20, 20), x) for x in s)\n",
    "\n",
    "print(\"List\", x2)\n",
    "print(\"List2\", x_even)\n",
    "print(\"Tuple\", t)\n",
    "print(\"Set\", s)\n",
    "print(\"Dict\", d)\n",
    "print(\"Generator\", g) # Hasn't evaluated anything yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Conclusion\n",
    "That's all for now! Please let me know if you have questions or want to know more about any of this. I'd love to look into it with you, I really enjoy thinking and talking about this stuff. Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
